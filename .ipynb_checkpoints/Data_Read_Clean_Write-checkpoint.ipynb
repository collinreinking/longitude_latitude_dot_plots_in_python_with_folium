{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enable matplotlib to display in jupyter notebook & import it\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from geopy.geocoders import Nominatim #used in filling missing zipcodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean Listings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#listings.csv READING\n",
    "\n",
    "LISTINGS = 'data/listings.csv'\n",
    "\n",
    "#Choose which columns from the csv to read in.\n",
    "listings_cols = ['id',\n",
    "                'host_id',\n",
    "                'neighbourhood_cleansed',\n",
    "                'zipcode',\n",
    "                'latitude',\n",
    "                'longitude',\n",
    "                'property_type',\n",
    "                'room_type',\n",
    "                'accommodates',\n",
    "                'bathrooms',\n",
    "                'amenities',\n",
    "                'price',\n",
    "                'cleaning_fee',\n",
    "                'number_of_reviews',\n",
    "                'first_review',\n",
    "                'review_scores_rating',\n",
    "                'review_scores_accuracy',\n",
    "                'review_scores_cleanliness',\n",
    "                'review_scores_checkin',\n",
    "                'review_scores_communication',\n",
    "                'review_scores_location',\n",
    "                'review_scores_value',\n",
    "                'calculated_host_listings_count',\n",
    "                'reviews_per_month',\n",
    "                'bedrooms',\n",
    "                'beds',\n",
    "                'cancellation_policy',\n",
    "                'instant_bookable',\n",
    "                'minimum_nights',\n",
    "                'listing_url'] \n",
    "\n",
    "#Read in data from the csv\n",
    "listings = pd.read_csv(LISTINGS, usecols=listings_cols)\n",
    "\n",
    "#Rename any Columns as needed\n",
    "rename_dict = {'id':'listing_id',\n",
    "              'price':'listed_price'}\n",
    "\n",
    "listings.rename(columns = rename_dict, inplace=True)\n",
    "\n",
    "#use listing_id as index\n",
    "listings.set_index('listing_id', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "#         Cleaning          #\n",
    "#############################\n",
    "\n",
    "# 'zipcode' ##########\n",
    "#Paste this in to zipcode section of cleaning\n",
    "def latLonToZip(lat, lon):\n",
    "    '''Take in a latitude and longitude and return the zipcode for that location'''\n",
    "    geolocator = Nominatim()\n",
    "    try:\n",
    "        location = geolocator.reverse(str(lat)+','+str(lon))\n",
    "        z = re.compile('(\\s)([0-9]{5})(,\\sUnited)')\n",
    "        return z.findall(location[0])[0][1]\n",
    "    except:\n",
    "        print(str(lat)+','+str(lon),'-----',location)\n",
    "        return np.nan\n",
    "    \n",
    "    print(str(lat)+','+str(lon),'-----',location)\n",
    "    return np.nan\n",
    "#Find all missing zippcodes : missing_zipcodes\n",
    "missing_zipcodes = listings[listings.zipcode.isnull()].copy()\n",
    "\n",
    "#update rows that are missing zipcodes using latLonToZip to fill missin\n",
    "listings.zipcode.update(missing_zipcodes.apply(lambda x: latLonToZip(x['latitude'], x['longitude']), axis=1))\n",
    "\n",
    "#Remove 'zip+4' part of any zipcode \n",
    "listings.zipcode = listings.zipcode.apply(lambda x: str(x)[:5])\n",
    "\n",
    "# 'price' --> 'listed_price' ##########\n",
    "listings.listed_price = listings.listed_price.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "# 'cleaning_fee' ##########\n",
    "listings.cleaning_fee = listings.cleaning_fee.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "listings.cleaning_fee.fillna(0, inplace = True)\n",
    "\n",
    "# 'first_review' ##########\n",
    "listings.first_review = pd.to_datetime(listings.first_review)\n",
    "\n",
    "# 'amenities' ##########\n",
    "listings.amenities = listings.amenities.replace('[^\\w,\\s/]+','',regex=True).apply(lambda x: x.split(','))\n",
    "\n",
    "# 'instant_bookable' ##########\n",
    "listings.instant_bookable.replace({'f':False,'t':True}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean Calendar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calendar.csv READING\n",
    "\n",
    "CALENDAR = 'data/calendar.csv'\n",
    "\n",
    "#Read in all columns from calendar.csv : listing_id, date, available, price\n",
    "calendar = pd.read_csv(CALENDAR)\n",
    "\n",
    "\n",
    "#############################\n",
    "#         Cleaning          #\n",
    "#############################\n",
    "\n",
    "# 'date' ##########\n",
    "calendar.date = pd.to_datetime(calendar.date)\n",
    "\n",
    "# 'available' ##########\n",
    "calendar.available.replace({'f':False,'t':True}, inplace=True)\n",
    "\n",
    "# 'price' ##########\n",
    "calendar.price = calendar.price.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "#############################\n",
    "#         Augmenting        #\n",
    "#############################\n",
    "\n",
    "#create column to represent the day of the week for each date\n",
    "calendar['day_of_week'] = calendar.date.dt.dayofweek\n",
    "\n",
    "#Fill in missing price values for each listing using mean value for day of week from that listing\n",
    "calendar.price.fillna(calendar.groupby(['listing_id','day_of_week'])['price'].transform(\"mean\"), inplace=True)\n",
    "\n",
    "#create column for revenue generate by property (all prices for occupied days are modeled from mean)\n",
    "calendar['day_revenue'] = np.where(calendar.available, 0.0, calendar.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Using Calendar to Augment Listings DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Create a list of calendars seperated into 4 quarters\n",
    "quarter_dates = ['2016-09-06','2016-12-06','2017-03-06','2017-06-06','2017-09-06']\n",
    "q_cal = [calendar[calendar.date.isin(pd.date_range(quarter_dates[n], quarter_dates[n+1]))] for n in range(4)]\n",
    "\n",
    "#Revnue Per Quarter\n",
    "for n,q in enumerate(q_cal):\n",
    "    listings = listings.join(q_cal[n].groupby('listing_id').day_revenue.sum()).rename(columns={'day_revenue':'q'+str(n+1)+'_revenue'})\n",
    "\n",
    "#Occupancy Per Quarter\n",
    "for n,q in enumerate(q_cal):\n",
    "    q_len = len(pd.date_range(quarter_dates[n], quarter_dates[n+1]))\n",
    "    listings = listings.join((q_len - q_cal[n].groupby('listing_id').available.sum())/q_len).rename(columns={'available':'q'+str(n+1)+'_occupancy_rate'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Amenities Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amenities = list(set([item for item_list in listings.amenities for item in item_list]))\n",
    "for val in ['translation missing enhosting_amenity_49','translation missing enhosting_amenity_50', '']:\n",
    "    amenities.remove(val)\n",
    "\n",
    "amn_frame = pd.DataFrame(index = listings.index)\n",
    "\n",
    "#create the dummy for each amenity and rename the column as you go\n",
    "for amn in amenities:\n",
    "    amn_frame = amn_frame.join(listings.amenities.apply(lambda amns: amn in amns)).rename(columns={'amenities':amn})\n",
    "\n",
    "listings['analysis_table'] = listings.index\n",
    "listings['analysis_table'] = pd.DataFrame(listings.analysis_table.map(lambda x: amn_frame.loc[x]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings.to_pickle('data/listings_cleaned.pkl')\n",
    "calendar.to_pickle('data/calendar_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
